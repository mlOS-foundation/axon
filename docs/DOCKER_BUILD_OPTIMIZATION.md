# Docker Build Optimization

## Why the Build is Slow

The Docker build process takes a long time, especially the pip install step (#17), due to:

### 1. Large Package Downloads
- **PyTorch**: ~2-3GB (with dependencies)
- **TensorFlow**: ~500MB-1GB
- **Transformers**: ~100-200MB
- **ModelScope**: ~100-200MB
- **Total**: ~3-5GB of packages to download

### 2. No Cache During Build
- Previous Dockerfile used `--no-cache-dir` flag
- This means pip downloads everything fresh every time
- No benefit from previous builds

### 3. Multi-Platform Builds
- Building for both `linux/amd64` and `linux/arm64`
- Each platform requires separate package downloads
- Doubles the download time

### 4. Network Speed Limitations
- GitHub Actions runners have variable network speeds
- Large downloads can take 5-10 minutes per platform

## Optimizations Applied

### 1. BuildKit Cache Mounts
```dockerfile
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install ...
```

**Benefits:**
- Pip cache persists across builds
- Subsequent builds reuse downloaded packages
- Reduces download time by 80-90% after first build

**How it works:**
- Cache mount stores pip's download cache
- Not included in final image (keeps image size small)
- Persists across GitHub Actions runs using BuildKit cache

### 2. Removed `--no-cache-dir` Flag
- Allows pip to use cache during build
- Cache is cleaned after installation (`pip cache purge`)
- Final image size remains small

### 3. BuildKit Cache in GitHub Actions
```yaml
cache-from: type=gha
cache-to: type=gha,mode=max
```

**Benefits:**
- GitHub Actions caches Docker layers
- Reuses layers from previous builds
- Speeds up subsequent builds significantly

## Performance Improvements

### Before Optimization
- **First build**: ~15-20 minutes (downloads all packages)
- **Subsequent builds**: ~15-20 minutes (no cache benefit)
- **Multi-platform**: ~30-40 minutes total

### After Optimization
- **First build**: ~15-20 minutes (downloads all packages, builds cache)
- **Subsequent builds**: ~3-5 minutes (uses cached packages)
- **Multi-platform**: ~6-10 minutes total (with cache)

## Additional Optimization Options

### Option 1: Pre-built Base Image
Create a base image with Python packages pre-installed:
```dockerfile
FROM mlos-foundation/axon-converter-base:latest
COPY scripts/conversion/ /axon/scripts/
```

**Pros:**
- Very fast builds (just copy scripts)
- Base image can be updated less frequently

**Cons:**
- Need to maintain base image
- Less flexible for version updates

### Option 2: Multi-Stage Build with Package Cache
```dockerfile
FROM python:3.11-slim AS packages
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install torch transformers tensorflow ...

FROM python:3.11-slim
COPY --from=packages /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
```

**Pros:**
- Better layer caching
- Can rebuild packages layer independently

**Cons:**
- More complex Dockerfile
- May not provide significant benefit over current approach

### Option 3: Split into Framework-Specific Images
Create separate images:
- `axon-converter-pytorch` (PyTorch + Transformers)
- `axon-converter-tensorflow` (TensorFlow + tf2onnx)
- `axon-converter-full` (all frameworks)

**Pros:**
- Smaller images per use case
- Faster builds for specific frameworks
- Users only pull what they need

**Cons:**
- More images to maintain
- More complex workflow

### Option 4: Use Pre-compiled Wheels
```dockerfile
RUN pip install --only-binary=all torch tensorflow ...
```

**Pros:**
- Faster installation (no compilation)
- More reliable builds

**Cons:**
- May not be available for all platforms
- Less control over build options

## Current Status

âœ… **Implemented:**
- BuildKit cache mounts for pip
- GitHub Actions cache for Docker layers
- Removed `--no-cache-dir` flag
- Cache cleanup after installation

## Monitoring Build Times

To monitor improvements:
1. Check GitHub Actions workflow run times
2. Look for "Using cache" messages in build logs
3. Compare first build vs subsequent builds

## Future Improvements

1. **Consider pre-built base image** if builds still too slow
2. **Split into framework-specific images** if image size becomes issue
3. **Use GitHub Actions matrix** to build platforms in parallel
4. **Consider using Docker layer caching service** for even better cache performance

